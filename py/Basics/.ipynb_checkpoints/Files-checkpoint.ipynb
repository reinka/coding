{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'file' (pos 1) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-821031c3ce3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'file' (pos 1) not found"
     ]
    }
   ],
   "source": [
    "dir(open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function open in module io:\n",
      "\n",
      "open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)\n",
      "    Open file and return a stream.  Raise IOError upon failure.\n",
      "    \n",
      "    file is either a text or byte string giving the name (and the path\n",
      "    if the file isn't in the current working directory) of the file to\n",
      "    be opened or an integer file descriptor of the file to be\n",
      "    wrapped. (If a file descriptor is given, it is closed when the\n",
      "    returned I/O object is closed, unless closefd is set to False.)\n",
      "    \n",
      "    mode is an optional string that specifies the mode in which the file\n",
      "    is opened. It defaults to 'r' which means open for reading in text\n",
      "    mode.  Other common values are 'w' for writing (truncating the file if\n",
      "    it already exists), 'x' for creating and writing to a new file, and\n",
      "    'a' for appending (which on some Unix systems, means that all writes\n",
      "    append to the end of the file regardless of the current seek position).\n",
      "    In text mode, if encoding is not specified the encoding used is platform\n",
      "    dependent: locale.getpreferredencoding(False) is called to get the\n",
      "    current locale encoding. (For reading and writing raw bytes use binary\n",
      "    mode and leave encoding unspecified.) The available modes are:\n",
      "    \n",
      "    ========= ===============================================================\n",
      "    Character Meaning\n",
      "    --------- ---------------------------------------------------------------\n",
      "    'r'       open for reading (default)\n",
      "    'w'       open for writing, truncating the file first\n",
      "    'x'       create a new file and open it for writing\n",
      "    'a'       open for writing, appending to the end of the file if it exists\n",
      "    'b'       binary mode\n",
      "    't'       text mode (default)\n",
      "    '+'       open a disk file for updating (reading and writing)\n",
      "    'U'       universal newline mode (deprecated)\n",
      "    ========= ===============================================================\n",
      "    \n",
      "    The default mode is 'rt' (open for reading text). For binary random\n",
      "    access, the mode 'w+b' opens and truncates the file to 0 bytes, while\n",
      "    'r+b' opens the file without truncation. The 'x' mode implies 'w' and\n",
      "    raises an `FileExistsError` if the file already exists.\n",
      "    \n",
      "    Python distinguishes between files opened in binary and text modes,\n",
      "    even when the underlying operating system doesn't. Files opened in\n",
      "    binary mode (appending 'b' to the mode argument) return contents as\n",
      "    bytes objects without any decoding. In text mode (the default, or when\n",
      "    't' is appended to the mode argument), the contents of the file are\n",
      "    returned as strings, the bytes having been first decoded using a\n",
      "    platform-dependent encoding or using the specified encoding if given.\n",
      "    \n",
      "    'U' mode is deprecated and will raise an exception in future versions\n",
      "    of Python.  It has no effect in Python 3.  Use newline to control\n",
      "    universal newlines mode.\n",
      "    \n",
      "    buffering is an optional integer used to set the buffering policy.\n",
      "    Pass 0 to switch buffering off (only allowed in binary mode), 1 to select\n",
      "    line buffering (only usable in text mode), and an integer > 1 to indicate\n",
      "    the size of a fixed-size chunk buffer.  When no buffering argument is\n",
      "    given, the default buffering policy works as follows:\n",
      "    \n",
      "    * Binary files are buffered in fixed-size chunks; the size of the buffer\n",
      "      is chosen using a heuristic trying to determine the underlying device's\n",
      "      \"block size\" and falling back on `io.DEFAULT_BUFFER_SIZE`.\n",
      "      On many systems, the buffer will typically be 4096 or 8192 bytes long.\n",
      "    \n",
      "    * \"Interactive\" text files (files for which isatty() returns True)\n",
      "      use line buffering.  Other text files use the policy described above\n",
      "      for binary files.\n",
      "    \n",
      "    encoding is the name of the encoding used to decode or encode the\n",
      "    file. This should only be used in text mode. The default encoding is\n",
      "    platform dependent, but any encoding supported by Python can be\n",
      "    passed.  See the codecs module for the list of supported encodings.\n",
      "    \n",
      "    errors is an optional string that specifies how encoding errors are to\n",
      "    be handled---this argument should not be used in binary mode. Pass\n",
      "    'strict' to raise a ValueError exception if there is an encoding error\n",
      "    (the default of None has the same effect), or pass 'ignore' to ignore\n",
      "    errors. (Note that ignoring encoding errors can lead to data loss.)\n",
      "    See the documentation for codecs.register or run 'help(codecs.Codec)'\n",
      "    for a list of the permitted encoding error strings.\n",
      "    \n",
      "    newline controls how universal newlines works (it only applies to text\n",
      "    mode). It can be None, '', '\\n', '\\r', and '\\r\\n'.  It works as\n",
      "    follows:\n",
      "    \n",
      "    * On input, if newline is None, universal newlines mode is\n",
      "      enabled. Lines in the input can end in '\\n', '\\r', or '\\r\\n', and\n",
      "      these are translated into '\\n' before being returned to the\n",
      "      caller. If it is '', universal newline mode is enabled, but line\n",
      "      endings are returned to the caller untranslated. If it has any of\n",
      "      the other legal values, input lines are only terminated by the given\n",
      "      string, and the line ending is returned to the caller untranslated.\n",
      "    \n",
      "    * On output, if newline is None, any '\\n' characters written are\n",
      "      translated to the system default line separator, os.linesep. If\n",
      "      newline is '' or '\\n', no translation takes place. If newline is any\n",
      "      of the other legal values, any '\\n' characters written are translated\n",
      "      to the given string.\n",
      "    \n",
      "    If closefd is False, the underlying file descriptor will be kept open\n",
      "    when the file is closed. This does not work when a file name is given\n",
      "    and must be True in that case.\n",
      "    \n",
      "    A custom opener can be used by passing a callable as *opener*. The\n",
      "    underlying file descriptor for the file object is then obtained by\n",
      "    calling *opener* with (*file*, *flags*). *opener* must return an open\n",
      "    file descriptor (passing os.open as *opener* results in functionality\n",
      "    similar to passing None).\n",
      "    \n",
      "    open() returns a file object whose type depends on the mode, and\n",
      "    through which the standard file operations such as reading and writing\n",
      "    are performed. When open() is used to open a file in a text mode ('w',\n",
      "    'r', 'wt', 'rt', etc.), it returns a TextIOWrapper. When used to open\n",
      "    a file in a binary mode, the returned class varies: in read binary\n",
      "    mode, it returns a BufferedReader; in write binary and append binary\n",
      "    modes, it returns a BufferedWriter, and in read/write mode, it returns\n",
      "    a BufferedRandom.\n",
      "    \n",
      "    It is also possible to use a string or bytearray as a file for both\n",
      "    reading and writing. For strings StringIO can be used like a file\n",
      "    opened in a text mode, and for bytes a BytesIO can be used like a file\n",
      "    opened in a binary mode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'locale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a33788571a9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'locale' is not defined"
     ]
    }
   ],
   "source": [
    "locale.getpreferredencoding(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'isatty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7bbd735dcb67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misatty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'isatty' is not defined"
     ]
    }
   ],
   "source": [
    "help(isatty())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing and reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('test.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write('hello world\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write('goodbye file\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('test.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goodbye file\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world\\ngoodbye file\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('test.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "goodbye file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(open('test.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "\n",
      "goodbye file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('test.txt', 'r'):\n",
    "    print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "goodbye file\n"
     ]
    }
   ],
   "source": [
    "for line in open('test.txt', 'r'):\n",
    "    print (line, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Python objects in files: Conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y, z = 50, 60, 70\n",
    "s = 'spam'\n",
    "lst = [1,2,3]\n",
    "d = dict(zip(list('ab'), range(1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create output txt file\n",
    "\n",
    "f = open('datafile.txt', 'w')\n",
    "f.write(s + '\\n')\n",
    "f.write('%s %s %s\\n' % (x,y,z))\n",
    "f.write(str(lst) + '$' + str(d) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"spam\\n50 60 70\\n[1, 2, 3]${'a': 1, 'b': 2}\\n\""
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = open('datafile.txt','r').read()\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "50 60 70\n",
      "[1, 2, 3]${'a': 1, 'b': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "50 60 70\n",
      "[1, 2, 3]${'a': 1, 'b': 2}\n"
     ]
    }
   ],
   "source": [
    "for line in open('datafile.txt'):\n",
    "    print (line, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('datafile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam\\n'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function strip:\n",
      "\n",
      "strip(...) method of builtins.str instance\n",
      "    S.strip([chars]) -> str\n",
      "    \n",
      "    Return a copy of the string S with leading and trailing\n",
      "    whitespace removed.\n",
      "    If chars is given and not None, remove characters in chars instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(line.strip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function rstrip:\n",
      "\n",
      "rstrip(...) method of builtins.str instance\n",
      "    S.rstrip([chars]) -> str\n",
      "    \n",
      "    Return a copy of the string S with trailing whitespace removed.\n",
      "    If chars is given and not None, remove characters in chars instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help(line.rstrip)\n",
    "line = line.rstrip()\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function split:\n",
      "\n",
      "split(...) method of builtins.str instance\n",
      "    S.split(sep=None, maxsplit=-1) -> list of strings\n",
      "    \n",
      "    Return a list of the words in S, using sep as the\n",
      "    delimiter string.  If maxsplit is given, at most maxsplit\n",
      "    splits are done. If sep is not specified or is None, any\n",
      "    whitespace string is a separator and empty strings are\n",
      "    removed from the result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tup = f.readline()\n",
    "help(tup.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['50', '60', '70\\n']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['50', '60', '70']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = tup.split()\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 60, 70)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup_final = tuple([int(num) for num in tup])\n",
    "tup_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tup_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using eval to split list and dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function eval in module builtins:\n",
      "\n",
      "eval(source, globals=None, locals=None, /)\n",
      "    Evaluate the given source in the context of globals and locals.\n",
      "    \n",
      "    The source may be a string representing a Python expression\n",
      "    or a code object as returned by compile().\n",
      "    The globals must be a dictionary and locals can be any mapping,\n",
      "    defaulting to the current globals and locals.\n",
      "    If only globals is given, locals defaults to it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[1, 2, 3]${'a': 1, 'b': 2}\\n\""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line3 = f.readline()\n",
    "line3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[1, 2, 3]', \"{'a': 1, 'b': 2}\\n\"]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line3 = line3.split('$')\n",
    "line3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval() arg 1 must be a string, bytes or code object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-af097febdb53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: eval() arg 1 must be a string, bytes or code object"
     ]
    }
   ],
   "source": [
    "eval(line3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(line3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], {'a': 1, 'b': 2}]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[eval(x) for x in line3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storing native python objects: pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module pickle:\n",
      "\n",
      "NAME\n",
      "    pickle - Create portable serialized representations of Python objects.\n",
      "\n",
      "MODULE REFERENCE\n",
      "    http://docs.python.org/3.5/library/pickle\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "DESCRIPTION\n",
      "    See module copyreg for a mechanism for registering custom picklers.\n",
      "    See module pickletools source for extensive comments.\n",
      "    \n",
      "    Classes:\n",
      "    \n",
      "        Pickler\n",
      "        Unpickler\n",
      "    \n",
      "    Functions:\n",
      "    \n",
      "        dump(object, file)\n",
      "        dumps(object) -> string\n",
      "        load(file) -> object\n",
      "        loads(string) -> object\n",
      "    \n",
      "    Misc variables:\n",
      "    \n",
      "        __version__\n",
      "        format_version\n",
      "        compatible_formats\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        _pickle.PickleError\n",
      "            _pickle.PicklingError\n",
      "            _pickle.UnpicklingError\n",
      "    builtins.object\n",
      "        _pickle.Pickler\n",
      "        _pickle.Unpickler\n",
      "    \n",
      "    class PickleError(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PickleError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class Pickler(builtins.object)\n",
      "     |  This takes a binary file for writing a pickle data stream.\n",
      "     |  \n",
      "     |  The optional *protocol* argument tells the pickler to use the given\n",
      "     |  protocol; supported protocols are 0, 1, 2, 3 and 4.  The default\n",
      "     |  protocol is 3; a backward-incompatible protocol designed for Python 3.\n",
      "     |  \n",
      "     |  Specifying a negative protocol version selects the highest protocol\n",
      "     |  version supported.  The higher the protocol used, the more recent the\n",
      "     |  version of Python needed to read the pickle produced.\n",
      "     |  \n",
      "     |  The *file* argument must have a write() method that accepts a single\n",
      "     |  bytes argument. It can thus be a file object opened for binary\n",
      "     |  writing, an io.BytesIO instance, or any other custom object that meets\n",
      "     |  this interface.\n",
      "     |  \n",
      "     |  If *fix_imports* is True and protocol is less than 3, pickle will try\n",
      "     |  to map the new Python 3 names to the old module names used in Python\n",
      "     |  2, so that the pickle data stream is readable with Python 2.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __sizeof__(self, /)\n",
      "     |      Returns size in memory, in bytes.\n",
      "     |  \n",
      "     |  clear_memo(self, /)\n",
      "     |      Clears the pickler's \"memo\".\n",
      "     |      \n",
      "     |      The memo is the data structure that remembers which objects the\n",
      "     |      pickler has already seen, so that shared or recursive objects are\n",
      "     |      pickled by reference and not by value.  This method is useful when\n",
      "     |      re-using picklers.\n",
      "     |  \n",
      "     |  dump(self, obj, /)\n",
      "     |      Write a pickled representation of the given object to the open file.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  bin\n",
      "     |  \n",
      "     |  dispatch_table\n",
      "     |  \n",
      "     |  fast\n",
      "     |  \n",
      "     |  memo\n",
      "     |  \n",
      "     |  persistent_id\n",
      "    \n",
      "    class PicklingError(PickleError)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PicklingError\n",
      "     |      PickleError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors inherited from PickleError:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class Unpickler(builtins.object)\n",
      "     |  This takes a binary file for reading a pickle data stream.\n",
      "     |  \n",
      "     |  The protocol version of the pickle is detected automatically, so no\n",
      "     |  protocol argument is needed.  Bytes past the pickled object's\n",
      "     |  representation are ignored.\n",
      "     |  \n",
      "     |  The argument *file* must have two methods, a read() method that takes\n",
      "     |  an integer argument, and a readline() method that requires no\n",
      "     |  arguments.  Both methods should return bytes.  Thus *file* can be a\n",
      "     |  binary file object opened for reading, an io.BytesIO object, or any\n",
      "     |  other custom object that meets this interface.\n",
      "     |  \n",
      "     |  Optional keyword arguments are *fix_imports*, *encoding* and *errors*,\n",
      "     |  which are used to control compatiblity support for pickle stream\n",
      "     |  generated by Python 2.  If *fix_imports* is True, pickle will try to\n",
      "     |  map the old Python 2 names to the new names used in Python 3.  The\n",
      "     |  *encoding* and *errors* tell pickle how to decode 8-bit string\n",
      "     |  instances pickled by Python 2; these default to 'ASCII' and 'strict',\n",
      "     |  respectively.  The *encoding* can be 'bytes' to read these 8-bit\n",
      "     |  string instances as bytes objects.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __sizeof__(self, /)\n",
      "     |      Returns size in memory, in bytes.\n",
      "     |  \n",
      "     |  find_class(self, module_name, global_name, /)\n",
      "     |      Return an object from a specified module.\n",
      "     |      \n",
      "     |      If necessary, the module will be imported. Subclasses may override\n",
      "     |      this method (e.g. to restrict unpickling of arbitrary classes and\n",
      "     |      functions).\n",
      "     |      \n",
      "     |      This method is called whenever a class or a function object is\n",
      "     |      needed.  Both arguments passed are str objects.\n",
      "     |  \n",
      "     |  load(self, /)\n",
      "     |      Load a pickle.\n",
      "     |      \n",
      "     |      Read a pickled object representation from the open file object given\n",
      "     |      in the constructor, and return the reconstituted object hierarchy\n",
      "     |      specified therein.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  memo\n",
      "     |  \n",
      "     |  persistent_load\n",
      "    \n",
      "    class UnpicklingError(PickleError)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UnpicklingError\n",
      "     |      PickleError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors inherited from PickleError:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "FUNCTIONS\n",
      "    dump(obj, file, protocol=None, *, fix_imports=True)\n",
      "        Write a pickled representation of obj to the open file object file.\n",
      "        \n",
      "        This is equivalent to ``Pickler(file, protocol).dump(obj)``, but may\n",
      "        be more efficient.\n",
      "        \n",
      "        The optional *protocol* argument tells the pickler to use the given\n",
      "        protocol supported protocols are 0, 1, 2, 3 and 4.  The default\n",
      "        protocol is 3; a backward-incompatible protocol designed for Python 3.\n",
      "        \n",
      "        Specifying a negative protocol version selects the highest protocol\n",
      "        version supported.  The higher the protocol used, the more recent the\n",
      "        version of Python needed to read the pickle produced.\n",
      "        \n",
      "        The *file* argument must have a write() method that accepts a single\n",
      "        bytes argument.  It can thus be a file object opened for binary\n",
      "        writing, an io.BytesIO instance, or any other custom object that meets\n",
      "        this interface.\n",
      "        \n",
      "        If *fix_imports* is True and protocol is less than 3, pickle will try\n",
      "        to map the new Python 3 names to the old module names used in Python\n",
      "        2, so that the pickle data stream is readable with Python 2.\n",
      "    \n",
      "    dumps(obj, protocol=None, *, fix_imports=True)\n",
      "        Return the pickled representation of the object as a bytes object.\n",
      "        \n",
      "        The optional *protocol* argument tells the pickler to use the given\n",
      "        protocol; supported protocols are 0, 1, 2, 3 and 4.  The default\n",
      "        protocol is 3; a backward-incompatible protocol designed for Python 3.\n",
      "        \n",
      "        Specifying a negative protocol version selects the highest protocol\n",
      "        version supported.  The higher the protocol used, the more recent the\n",
      "        version of Python needed to read the pickle produced.\n",
      "        \n",
      "        If *fix_imports* is True and *protocol* is less than 3, pickle will\n",
      "        try to map the new Python 3 names to the old module names used in\n",
      "        Python 2, so that the pickle data stream is readable with Python 2.\n",
      "    \n",
      "    load(file, *, fix_imports=True, encoding='ASCII', errors='strict')\n",
      "        Read and return an object from the pickle data stored in a file.\n",
      "        \n",
      "        This is equivalent to ``Unpickler(file).load()``, but may be more\n",
      "        efficient.\n",
      "        \n",
      "        The protocol version of the pickle is detected automatically, so no\n",
      "        protocol argument is needed.  Bytes past the pickled object's\n",
      "        representation are ignored.\n",
      "        \n",
      "        The argument *file* must have two methods, a read() method that takes\n",
      "        an integer argument, and a readline() method that requires no\n",
      "        arguments.  Both methods should return bytes.  Thus *file* can be a\n",
      "        binary file object opened for reading, an io.BytesIO object, or any\n",
      "        other custom object that meets this interface.\n",
      "        \n",
      "        Optional keyword arguments are *fix_imports*, *encoding* and *errors*,\n",
      "        which are used to control compatiblity support for pickle stream\n",
      "        generated by Python 2.  If *fix_imports* is True, pickle will try to\n",
      "        map the old Python 2 names to the new names used in Python 3.  The\n",
      "        *encoding* and *errors* tell pickle how to decode 8-bit string\n",
      "        instances pickled by Python 2; these default to 'ASCII' and 'strict',\n",
      "        respectively.  The *encoding* can be 'bytes' to read these 8-bit\n",
      "        string instances as bytes objects.\n",
      "    \n",
      "    loads(data, *, fix_imports=True, encoding='ASCII', errors='strict')\n",
      "        Read and return an object from the given pickle data.\n",
      "        \n",
      "        The protocol version of the pickle is detected automatically, so no\n",
      "        protocol argument is needed.  Bytes past the pickled object's\n",
      "        representation are ignored.\n",
      "        \n",
      "        Optional keyword arguments are *fix_imports*, *encoding* and *errors*,\n",
      "        which are used to control compatiblity support for pickle stream\n",
      "        generated by Python 2.  If *fix_imports* is True, pickle will try to\n",
      "        map the old Python 2 names to the new names used in Python 3.  The\n",
      "        *encoding* and *errors* tell pickle how to decode 8-bit string\n",
      "        instances pickled by Python 2; these default to 'ASCII' and 'strict',\n",
      "        respectively.  The *encoding* can be 'bytes' to read these 8-bit\n",
      "        string instances as bytes objects.\n",
      "\n",
      "DATA\n",
      "    ADDITEMS = b'\\x90'\n",
      "    APPEND = b'a'\n",
      "    APPENDS = b'e'\n",
      "    BINBYTES = b'B'\n",
      "    BINBYTES8 = b'\\x8e'\n",
      "    BINFLOAT = b'G'\n",
      "    BINGET = b'h'\n",
      "    BININT = b'J'\n",
      "    BININT1 = b'K'\n",
      "    BININT2 = b'M'\n",
      "    BINPERSID = b'Q'\n",
      "    BINPUT = b'q'\n",
      "    BINSTRING = b'T'\n",
      "    BINUNICODE = b'X'\n",
      "    BINUNICODE8 = b'\\x8d'\n",
      "    BUILD = b'b'\n",
      "    DEFAULT_PROTOCOL = 3\n",
      "    DICT = b'd'\n",
      "    DUP = b'2'\n",
      "    EMPTY_DICT = b'}'\n",
      "    EMPTY_LIST = b']'\n",
      "    EMPTY_SET = b'\\x8f'\n",
      "    EMPTY_TUPLE = b')'\n",
      "    EXT1 = b'\\x82'\n",
      "    EXT2 = b'\\x83'\n",
      "    EXT4 = b'\\x84'\n",
      "    FALSE = b'I00\\n'\n",
      "    FLOAT = b'F'\n",
      "    FRAME = b'\\x95'\n",
      "    FROZENSET = b'\\x91'\n",
      "    GET = b'g'\n",
      "    GLOBAL = b'c'\n",
      "    HIGHEST_PROTOCOL = 4\n",
      "    INST = b'i'\n",
      "    INT = b'I'\n",
      "    LIST = b'l'\n",
      "    LONG = b'L'\n",
      "    LONG1 = b'\\x8a'\n",
      "    LONG4 = b'\\x8b'\n",
      "    LONG_BINGET = b'j'\n",
      "    LONG_BINPUT = b'r'\n",
      "    MARK = b'('\n",
      "    MEMOIZE = b'\\x94'\n",
      "    NEWFALSE = b'\\x89'\n",
      "    NEWOBJ = b'\\x81'\n",
      "    NEWOBJ_EX = b'\\x92'\n",
      "    NEWTRUE = b'\\x88'\n",
      "    NONE = b'N'\n",
      "    OBJ = b'o'\n",
      "    PERSID = b'P'\n",
      "    POP = b'0'\n",
      "    POP_MARK = b'1'\n",
      "    PROTO = b'\\x80'\n",
      "    PUT = b'p'\n",
      "    REDUCE = b'R'\n",
      "    SETITEM = b's'\n",
      "    SETITEMS = b'u'\n",
      "    SHORT_BINBYTES = b'C'\n",
      "    SHORT_BINSTRING = b'U'\n",
      "    SHORT_BINUNICODE = b'\\x8c'\n",
      "    STACK_GLOBAL = b'\\x93'\n",
      "    STOP = b'.'\n",
      "    STRING = b'S'\n",
      "    TRUE = b'I01\\n'\n",
      "    TUPLE = b't'\n",
      "    TUPLE1 = b'\\x85'\n",
      "    TUPLE2 = b'\\x86'\n",
      "    TUPLE3 = b'\\x87'\n",
      "    UNICODE = b'V'\n",
      "    __all__ = ['PickleError', 'PicklingError', 'UnpicklingError', 'Pickler...\n",
      "\n",
      "FILE\n",
      "    /Users/slackoverflow/anaconda3/lib/python3.5/pickle.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alternative to eval: used when source can't be trusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "d = dict(a=1, b=2)\n",
    "f = open('pickle.txt', 'wb')\n",
    "pickle.dump(d,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-95949daa99e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pickle.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/slackoverflow/anaconda3/lib/python3.5/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "f = open('pickle.txt')\n",
    "test = pickle.load(f)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('pickle.txt', 'rb')\n",
    "test = pickle.load(f)       #pickle module performs object serialization\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module shelve:\n",
      "\n",
      "NAME\n",
      "    shelve - Manage shelves of pickled objects.\n",
      "\n",
      "MODULE REFERENCE\n",
      "    http://docs.python.org/3.5/library/shelve\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "DESCRIPTION\n",
      "    A \"shelf\" is a persistent, dictionary-like object.  The difference\n",
      "    with dbm databases is that the values (not the keys!) in a shelf can\n",
      "    be essentially arbitrary Python objects -- anything that the \"pickle\"\n",
      "    module can handle.  This includes most class instances, recursive data\n",
      "    types, and objects containing lots of shared sub-objects.  The keys\n",
      "    are ordinary strings.\n",
      "    \n",
      "    To summarize the interface (key is a string, data is an arbitrary\n",
      "    object):\n",
      "    \n",
      "            import shelve\n",
      "            d = shelve.open(filename) # open, with (g)dbm filename -- no suffix\n",
      "    \n",
      "            d[key] = data   # store data at key (overwrites old data if\n",
      "                            # using an existing key)\n",
      "            data = d[key]   # retrieve a COPY of the data at key (raise\n",
      "                            # KeyError if no such key) -- NOTE that this\n",
      "                            # access returns a *copy* of the entry!\n",
      "            del d[key]      # delete data stored at key (raises KeyError\n",
      "                            # if no such key)\n",
      "            flag = key in d # true if the key exists\n",
      "            list = d.keys() # a list of all existing keys (slow!)\n",
      "    \n",
      "            d.close()       # close it\n",
      "    \n",
      "    Dependent on the implementation, closing a persistent dictionary may\n",
      "    or may not be necessary to flush changes to disk.\n",
      "    \n",
      "    Normally, d[key] returns a COPY of the entry.  This needs care when\n",
      "    mutable entries are mutated: for example, if d[key] is a list,\n",
      "            d[key].append(anitem)\n",
      "    does NOT modify the entry d[key] itself, as stored in the persistent\n",
      "    mapping -- it only modifies the copy, which is then immediately\n",
      "    discarded, so that the append has NO effect whatsoever.  To append an\n",
      "    item to d[key] in a way that will affect the persistent mapping, use:\n",
      "            data = d[key]\n",
      "            data.append(anitem)\n",
      "            d[key] = data\n",
      "    \n",
      "    To avoid the problem with mutable entries, you may pass the keyword\n",
      "    argument writeback=True in the call to shelve.open.  When you use:\n",
      "            d = shelve.open(filename, writeback=True)\n",
      "    then d keeps a cache of all entries you access, and writes them all back\n",
      "    to the persistent mapping when you call d.close().  This ensures that\n",
      "    such usage as d[key].append(anitem) works as intended.\n",
      "    \n",
      "    However, using keyword argument writeback=True may consume vast amount\n",
      "    of memory for the cache, and it may make d.close() very slow, if you\n",
      "    access many of d's entries after opening it in this way: d has no way to\n",
      "    check which of the entries you access are mutable and/or which ones you\n",
      "    actually mutate, so it must cache, and write back at close, all of the\n",
      "    entries that you access.  You can call d.sync() to write back all the\n",
      "    entries in the cache, and empty the cache (d.sync() also synchronizes\n",
      "    the persistent dictionary on disk, if feasible).\n",
      "\n",
      "CLASSES\n",
      "    collections.abc.MutableMapping(collections.abc.Mapping)\n",
      "        Shelf\n",
      "            BsdDbShelf\n",
      "            DbfilenameShelf\n",
      "    \n",
      "    class BsdDbShelf(Shelf)\n",
      "     |  Shelf implementation using the \"BSD\" db interface.\n",
      "     |  \n",
      "     |  This adds methods first(), next(), previous(), last() and\n",
      "     |  set_location() that have no counterpart in [g]dbm databases.\n",
      "     |  \n",
      "     |  The actual database must be opened using one of the \"bsddb\"\n",
      "     |  modules \"open\" routines (i.e. bsddb.hashopen, bsddb.btopen or\n",
      "     |  bsddb.rnopen) and passed to the constructor.\n",
      "     |  \n",
      "     |  See the module's __doc__ string for an overview of the interface.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BsdDbShelf\n",
      "     |      Shelf\n",
      "     |      collections.abc.MutableMapping\n",
      "     |      collections.abc.Mapping\n",
      "     |      collections.abc.Sized\n",
      "     |      collections.abc.Iterable\n",
      "     |      collections.abc.Container\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dict, protocol=None, writeback=False, keyencoding='utf-8')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  first(self)\n",
      "     |  \n",
      "     |  last(self)\n",
      "     |  \n",
      "     |  next(self)\n",
      "     |  \n",
      "     |  previous(self)\n",
      "     |  \n",
      "     |  set_location(self, key)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Shelf:\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, type, value, traceback)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  sync(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Shelf:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.MutableMapping:\n",
      "     |  \n",
      "     |  clear(self)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |  \n",
      "     |  pop(self, key, default=<object object at 0x10192e050>)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised.\n",
      "     |  \n",
      "     |  popitem(self)\n",
      "     |      D.popitem() -> (k, v), remove and return some (key, value) pair\n",
      "     |      as a 2-tuple; but raise KeyError if D is empty.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      "     |  \n",
      "     |  update(*args, **kwds)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      "     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  items(self)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  keys(self)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  values(self)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.Sized:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "    \n",
      "    class DbfilenameShelf(Shelf)\n",
      "     |  Shelf implementation using the \"dbm\" generic dbm interface.\n",
      "     |  \n",
      "     |  This is initialized with the filename for the dbm database.\n",
      "     |  See the module's __doc__ string for an overview of the interface.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DbfilenameShelf\n",
      "     |      Shelf\n",
      "     |      collections.abc.MutableMapping\n",
      "     |      collections.abc.Mapping\n",
      "     |      collections.abc.Sized\n",
      "     |      collections.abc.Iterable\n",
      "     |      collections.abc.Container\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, filename, flag='c', protocol=None, writeback=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Shelf:\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, type, value, traceback)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  sync(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Shelf:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.MutableMapping:\n",
      "     |  \n",
      "     |  clear(self)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |  \n",
      "     |  pop(self, key, default=<object object at 0x10192e050>)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised.\n",
      "     |  \n",
      "     |  popitem(self)\n",
      "     |      D.popitem() -> (k, v), remove and return some (key, value) pair\n",
      "     |      as a 2-tuple; but raise KeyError if D is empty.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      "     |  \n",
      "     |  update(*args, **kwds)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      "     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  items(self)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  keys(self)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  values(self)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.Sized:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "    \n",
      "    class Shelf(collections.abc.MutableMapping)\n",
      "     |  Base class for shelf implementations.\n",
      "     |  \n",
      "     |  This is initialized with a dictionary-like object.\n",
      "     |  See the module's __doc__ string for an overview of the interface.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Shelf\n",
      "     |      collections.abc.MutableMapping\n",
      "     |      collections.abc.Mapping\n",
      "     |      collections.abc.Sized\n",
      "     |      collections.abc.Iterable\n",
      "     |      collections.abc.Container\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, type, value, traceback)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __init__(self, dict, protocol=None, writeback=False, keyencoding='utf-8')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  sync(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.MutableMapping:\n",
      "     |  \n",
      "     |  clear(self)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |  \n",
      "     |  pop(self, key, default=<object object at 0x10192e050>)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised.\n",
      "     |  \n",
      "     |  popitem(self)\n",
      "     |      D.popitem() -> (k, v), remove and return some (key, value) pair\n",
      "     |      as a 2-tuple; but raise KeyError if D is empty.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      "     |  \n",
      "     |  update(*args, **kwds)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      "     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  items(self)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  keys(self)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  values(self)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.Sized:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "\n",
      "FUNCTIONS\n",
      "    open(filename, flag='c', protocol=None, writeback=False)\n",
      "        Open a persistent dictionary for reading and writing.\n",
      "        \n",
      "        The filename parameter is the base filename for the underlying\n",
      "        database.  As a side-effect, an extension may be added to the\n",
      "        filename and more than one file may be created.  The optional flag\n",
      "        parameter has the same interpretation as the flag parameter of\n",
      "        dbm.open(). The optional protocol parameter specifies the\n",
      "        version of the pickle protocol (0, 1, or 2).\n",
      "        \n",
      "        See the module's __doc__ string for an overview of the interface.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Shelf', 'BsdDbShelf', 'DbfilenameShelf', 'open']\n",
      "\n",
      "FILE\n",
      "    /Users/slackoverflow/anaconda3/lib/python3.5/shelve.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shelve\n",
    "help(shelve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## storing python objects in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package json:\n",
      "\n",
      "NAME\n",
      "    json\n",
      "\n",
      "MODULE REFERENCE\n",
      "    http://docs.python.org/3.5/library/json\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "DESCRIPTION\n",
      "    JSON (JavaScript Object Notation) <http://json.org> is a subset of\n",
      "    JavaScript syntax (ECMA-262 3rd edition) used as a lightweight data\n",
      "    interchange format.\n",
      "    \n",
      "    :mod:`json` exposes an API familiar to users of the standard library\n",
      "    :mod:`marshal` and :mod:`pickle` modules.  It is derived from a\n",
      "    version of the externally maintained simplejson library.\n",
      "    \n",
      "    Encoding basic Python object hierarchies::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])\n",
      "        '[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]'\n",
      "        >>> print(json.dumps(\"\\\"foo\\bar\"))\n",
      "        \"\\\"foo\\bar\"\n",
      "        >>> print(json.dumps('\\u1234'))\n",
      "        \"\\u1234\"\n",
      "        >>> print(json.dumps('\\\\'))\n",
      "        \"\\\\\"\n",
      "        >>> print(json.dumps({\"c\": 0, \"b\": 0, \"a\": 0}, sort_keys=True))\n",
      "        {\"a\": 0, \"b\": 0, \"c\": 0}\n",
      "        >>> from io import StringIO\n",
      "        >>> io = StringIO()\n",
      "        >>> json.dump(['streaming API'], io)\n",
      "        >>> io.getvalue()\n",
      "        '[\"streaming API\"]'\n",
      "    \n",
      "    Compact encoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> from collections import OrderedDict\n",
      "        >>> mydict = OrderedDict([('4', 5), ('6', 7)])\n",
      "        >>> json.dumps([1,2,3,mydict], separators=(',', ':'))\n",
      "        '[1,2,3,{\"4\":5,\"6\":7}]'\n",
      "    \n",
      "    Pretty printing::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> print(json.dumps({'4': 5, '6': 7}, sort_keys=True, indent=4))\n",
      "        {\n",
      "            \"4\": 5,\n",
      "            \"6\": 7\n",
      "        }\n",
      "    \n",
      "    Decoding JSON::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> obj = ['foo', {'bar': ['baz', None, 1.0, 2]}]\n",
      "        >>> json.loads('[\"foo\", {\"bar\":[\"baz\", null, 1.0, 2]}]') == obj\n",
      "        True\n",
      "        >>> json.loads('\"\\\\\"foo\\\\bar\"') == '\"foo\\x08ar'\n",
      "        True\n",
      "        >>> from io import StringIO\n",
      "        >>> io = StringIO('[\"streaming API\"]')\n",
      "        >>> json.load(io)[0] == 'streaming API'\n",
      "        True\n",
      "    \n",
      "    Specializing JSON object decoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> def as_complex(dct):\n",
      "        ...     if '__complex__' in dct:\n",
      "        ...         return complex(dct['real'], dct['imag'])\n",
      "        ...     return dct\n",
      "        ...\n",
      "        >>> json.loads('{\"__complex__\": true, \"real\": 1, \"imag\": 2}',\n",
      "        ...     object_hook=as_complex)\n",
      "        (1+2j)\n",
      "        >>> from decimal import Decimal\n",
      "        >>> json.loads('1.1', parse_float=Decimal) == Decimal('1.1')\n",
      "        True\n",
      "    \n",
      "    Specializing JSON object encoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> def encode_complex(obj):\n",
      "        ...     if isinstance(obj, complex):\n",
      "        ...         return [obj.real, obj.imag]\n",
      "        ...     raise TypeError(repr(o) + \" is not JSON serializable\")\n",
      "        ...\n",
      "        >>> json.dumps(2 + 1j, default=encode_complex)\n",
      "        '[2.0, 1.0]'\n",
      "        >>> json.JSONEncoder(default=encode_complex).encode(2 + 1j)\n",
      "        '[2.0, 1.0]'\n",
      "        >>> ''.join(json.JSONEncoder(default=encode_complex).iterencode(2 + 1j))\n",
      "        '[2.0, 1.0]'\n",
      "    \n",
      "    \n",
      "    Using json.tool from the shell to validate and pretty-print::\n",
      "    \n",
      "        $ echo '{\"json\":\"obj\"}' | python -m json.tool\n",
      "        {\n",
      "            \"json\": \"obj\"\n",
      "        }\n",
      "        $ echo '{ 1.2:3.4}' | python -m json.tool\n",
      "        Expecting property name enclosed in double quotes: line 1 column 3 (char 2)\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    decoder\n",
      "    encoder\n",
      "    scanner\n",
      "    tool\n",
      "\n",
      "CLASSES\n",
      "    builtins.ValueError(builtins.Exception)\n",
      "        json.decoder.JSONDecodeError\n",
      "    builtins.object\n",
      "        json.decoder.JSONDecoder\n",
      "        json.encoder.JSONEncoder\n",
      "    \n",
      "    class JSONDecodeError(builtins.ValueError)\n",
      "     |  Subclass of ValueError with the following additional properties:\n",
      "     |  \n",
      "     |  msg: The unformatted error message\n",
      "     |  doc: The JSON document being parsed\n",
      "     |  pos: The start index of doc where parsing failed\n",
      "     |  lineno: The line corresponding to pos\n",
      "     |  colno: The column corresponding to pos\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      JSONDecodeError\n",
      "     |      builtins.ValueError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, msg, doc, pos)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.ValueError:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class JSONDecoder(builtins.object)\n",
      "     |  Simple JSON <http://json.org> decoder\n",
      "     |  \n",
      "     |  Performs the following translations in decoding by default:\n",
      "     |  \n",
      "     |  +---------------+-------------------+\n",
      "     |  | JSON          | Python            |\n",
      "     |  +===============+===================+\n",
      "     |  | object        | dict              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | array         | list              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | string        | str               |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | number (int)  | int               |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | number (real) | float             |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | true          | True              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | false         | False             |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | null          | None              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  \n",
      "     |  It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as\n",
      "     |  their corresponding ``float`` values, which is outside the JSON spec.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None)\n",
      "     |      ``object_hook``, if specified, will be called with the result\n",
      "     |      of every JSON object decoded and its return value will be used in\n",
      "     |      place of the given ``dict``.  This can be used to provide custom\n",
      "     |      deserializations (e.g. to support JSON-RPC class hinting).\n",
      "     |      \n",
      "     |      ``object_pairs_hook``, if specified will be called with the result of\n",
      "     |      every JSON object decoded with an ordered list of pairs.  The return\n",
      "     |      value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "     |      This feature can be used to implement custom decoders that rely on the\n",
      "     |      order that the key and value pairs are decoded (for example,\n",
      "     |      collections.OrderedDict will remember the order of insertion). If\n",
      "     |      ``object_hook`` is also defined, the ``object_pairs_hook`` takes\n",
      "     |      priority.\n",
      "     |      \n",
      "     |      ``parse_float``, if specified, will be called with the string\n",
      "     |      of every JSON float to be decoded. By default this is equivalent to\n",
      "     |      float(num_str). This can be used to use another datatype or parser\n",
      "     |      for JSON floats (e.g. decimal.Decimal).\n",
      "     |      \n",
      "     |      ``parse_int``, if specified, will be called with the string\n",
      "     |      of every JSON int to be decoded. By default this is equivalent to\n",
      "     |      int(num_str). This can be used to use another datatype or parser\n",
      "     |      for JSON integers (e.g. float).\n",
      "     |      \n",
      "     |      ``parse_constant``, if specified, will be called with one of the\n",
      "     |      following strings: -Infinity, Infinity, NaN.\n",
      "     |      This can be used to raise an exception if invalid JSON numbers\n",
      "     |      are encountered.\n",
      "     |      \n",
      "     |      If ``strict`` is false (true is the default), then control\n",
      "     |      characters will be allowed inside strings.  Control characters in\n",
      "     |      this context are those with character codes in the 0-31 range,\n",
      "     |      including ``'\\t'`` (tab), ``'\\n'``, ``'\\r'`` and ``'\\0'``.\n",
      "     |  \n",
      "     |  decode(self, s, _w=<built-in method match of _sre.SRE_Pattern object at 0x101bdb930>)\n",
      "     |      Return the Python representation of ``s`` (a ``str`` instance\n",
      "     |      containing a JSON document).\n",
      "     |  \n",
      "     |  raw_decode(self, s, idx=0)\n",
      "     |      Decode a JSON document from ``s`` (a ``str`` beginning with\n",
      "     |      a JSON document) and return a 2-tuple of the Python\n",
      "     |      representation and the index in ``s`` where the document ended.\n",
      "     |      \n",
      "     |      This can be used to decode a JSON document from a string that may\n",
      "     |      have extraneous data at the end.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class JSONEncoder(builtins.object)\n",
      "     |  Extensible JSON <http://json.org> encoder for Python data structures.\n",
      "     |  \n",
      "     |  Supports the following objects and types by default:\n",
      "     |  \n",
      "     |  +-------------------+---------------+\n",
      "     |  | Python            | JSON          |\n",
      "     |  +===================+===============+\n",
      "     |  | dict              | object        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | list, tuple       | array         |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | str               | string        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | int, float        | number        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | True              | true          |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | False             | false         |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | None              | null          |\n",
      "     |  +-------------------+---------------+\n",
      "     |  \n",
      "     |  To extend this to recognize other objects, subclass and implement a\n",
      "     |  ``.default()`` method with another method that returns a serializable\n",
      "     |  object for ``o`` if possible, otherwise it should call the superclass\n",
      "     |  implementation (to raise ``TypeError``).\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)\n",
      "     |      Constructor for JSONEncoder, with sensible defaults.\n",
      "     |      \n",
      "     |      If skipkeys is false, then it is a TypeError to attempt\n",
      "     |      encoding of keys that are not str, int, float or None.  If\n",
      "     |      skipkeys is True, such items are simply skipped.\n",
      "     |      \n",
      "     |      If ensure_ascii is true, the output is guaranteed to be str\n",
      "     |      objects with all incoming non-ASCII characters escaped.  If\n",
      "     |      ensure_ascii is false, the output can contain non-ASCII characters.\n",
      "     |      \n",
      "     |      If check_circular is true, then lists, dicts, and custom encoded\n",
      "     |      objects will be checked for circular references during encoding to\n",
      "     |      prevent an infinite recursion (which would cause an OverflowError).\n",
      "     |      Otherwise, no such check takes place.\n",
      "     |      \n",
      "     |      If allow_nan is true, then NaN, Infinity, and -Infinity will be\n",
      "     |      encoded as such.  This behavior is not JSON specification compliant,\n",
      "     |      but is consistent with most JavaScript based encoders and decoders.\n",
      "     |      Otherwise, it will be a ValueError to encode such floats.\n",
      "     |      \n",
      "     |      If sort_keys is true, then the output of dictionaries will be\n",
      "     |      sorted by key; this is useful for regression tests to ensure\n",
      "     |      that JSON serializations can be compared on a day-to-day basis.\n",
      "     |      \n",
      "     |      If indent is a non-negative integer, then JSON array\n",
      "     |      elements and object members will be pretty-printed with that\n",
      "     |      indent level.  An indent level of 0 will only insert newlines.\n",
      "     |      None is the most compact representation.\n",
      "     |      \n",
      "     |      If specified, separators should be an (item_separator, key_separator)\n",
      "     |      tuple.  The default is (', ', ': ') if *indent* is ``None`` and\n",
      "     |      (',', ': ') otherwise.  To get the most compact JSON representation,\n",
      "     |      you should specify (',', ':') to eliminate whitespace.\n",
      "     |      \n",
      "     |      If specified, default is a function that gets called for objects\n",
      "     |      that can't otherwise be serialized.  It should return a JSON encodable\n",
      "     |      version of the object or raise a ``TypeError``.\n",
      "     |  \n",
      "     |  default(self, o)\n",
      "     |      Implement this method in a subclass such that it returns\n",
      "     |      a serializable object for ``o``, or calls the base implementation\n",
      "     |      (to raise a ``TypeError``).\n",
      "     |      \n",
      "     |      For example, to support arbitrary iterators, you could\n",
      "     |      implement default like this::\n",
      "     |      \n",
      "     |          def default(self, o):\n",
      "     |              try:\n",
      "     |                  iterable = iter(o)\n",
      "     |              except TypeError:\n",
      "     |                  pass\n",
      "     |              else:\n",
      "     |                  return list(iterable)\n",
      "     |              # Let the base class default method raise the TypeError\n",
      "     |              return JSONEncoder.default(self, o)\n",
      "     |  \n",
      "     |  encode(self, o)\n",
      "     |      Return a JSON string representation of a Python data structure.\n",
      "     |      \n",
      "     |      >>> from json.encoder import JSONEncoder\n",
      "     |      >>> JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]})\n",
      "     |      '{\"foo\": [\"bar\", \"baz\"]}'\n",
      "     |  \n",
      "     |  iterencode(self, o, _one_shot=False)\n",
      "     |      Encode the given object and yield each string\n",
      "     |      representation as available.\n",
      "     |      \n",
      "     |      For example::\n",
      "     |      \n",
      "     |          for chunk in JSONEncoder().iterencode(bigobject):\n",
      "     |              mysocket.write(chunk)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  item_separator = ', '\n",
      "     |  \n",
      "     |  key_separator = ': '\n",
      "\n",
      "FUNCTIONS\n",
      "    dump(obj, fp, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "        Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n",
      "        ``.write()``-supporting file-like object).\n",
      "        \n",
      "        If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "        instead of raising a ``TypeError``.\n",
      "        \n",
      "        If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n",
      "        contain non-ASCII characters if they appear in strings contained in\n",
      "        ``obj``. Otherwise, all such characters are escaped in JSON strings.\n",
      "        \n",
      "        If ``check_circular`` is false, then the circular reference check\n",
      "        for container types will be skipped and a circular reference will\n",
      "        result in an ``OverflowError`` (or worse).\n",
      "        \n",
      "        If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n",
      "        in strict compliance of the JSON specification, instead of using the\n",
      "        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "        \n",
      "        If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "        object members will be pretty-printed with that indent level. An indent\n",
      "        level of 0 will only insert newlines. ``None`` is the most compact\n",
      "        representation.\n",
      "        \n",
      "        If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "        you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "        \n",
      "        ``default(obj)`` is a function that should return a serializable version\n",
      "        of obj or raise TypeError. The default simply raises TypeError.\n",
      "        \n",
      "        If *sort_keys* is ``True`` (default: ``False``), then the output of\n",
      "        dictionaries will be sorted by key.\n",
      "        \n",
      "        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "        ``.default()`` method to serialize additional types), specify it with\n",
      "        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "    \n",
      "    dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "        Serialize ``obj`` to a JSON formatted ``str``.\n",
      "        \n",
      "        If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "        instead of raising a ``TypeError``.\n",
      "        \n",
      "        If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n",
      "        characters if they appear in strings contained in ``obj``. Otherwise, all\n",
      "        such characters are escaped in JSON strings.\n",
      "        \n",
      "        If ``check_circular`` is false, then the circular reference check\n",
      "        for container types will be skipped and a circular reference will\n",
      "        result in an ``OverflowError`` (or worse).\n",
      "        \n",
      "        If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n",
      "        strict compliance of the JSON specification, instead of using the\n",
      "        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "        \n",
      "        If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "        object members will be pretty-printed with that indent level. An indent\n",
      "        level of 0 will only insert newlines. ``None`` is the most compact\n",
      "        representation.\n",
      "        \n",
      "        If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "        you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "        \n",
      "        ``default(obj)`` is a function that should return a serializable version\n",
      "        of obj or raise TypeError. The default simply raises TypeError.\n",
      "        \n",
      "        If *sort_keys* is ``True`` (default: ``False``), then the output of\n",
      "        dictionaries will be sorted by key.\n",
      "        \n",
      "        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "        ``.default()`` method to serialize additional types), specify it with\n",
      "        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "    \n",
      "    load(fp, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)\n",
      "        Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\n",
      "        a JSON document) to a Python object.\n",
      "        \n",
      "        ``object_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decode (a ``dict``). The return value of\n",
      "        ``object_hook`` will be used instead of the ``dict``. This feature\n",
      "        can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n",
      "        \n",
      "        ``object_pairs_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decoded with an ordered list of pairs.  The\n",
      "        return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "        This feature can be used to implement custom decoders that rely on the\n",
      "        order that the key and value pairs are decoded (for example,\n",
      "        collections.OrderedDict will remember the order of insertion). If\n",
      "        ``object_hook`` is also defined, the ``object_pairs_hook`` takes priority.\n",
      "        \n",
      "        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n",
      "        kwarg; otherwise ``JSONDecoder`` is used.\n",
      "    \n",
      "    loads(s, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)\n",
      "        Deserialize ``s`` (a ``str`` instance containing a JSON\n",
      "        document) to a Python object.\n",
      "        \n",
      "        ``object_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decode (a ``dict``). The return value of\n",
      "        ``object_hook`` will be used instead of the ``dict``. This feature\n",
      "        can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n",
      "        \n",
      "        ``object_pairs_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decoded with an ordered list of pairs.  The\n",
      "        return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "        This feature can be used to implement custom decoders that rely on the\n",
      "        order that the key and value pairs are decoded (for example,\n",
      "        collections.OrderedDict will remember the order of insertion). If\n",
      "        ``object_hook`` is also defined, the ``object_pairs_hook`` takes priority.\n",
      "        \n",
      "        ``parse_float``, if specified, will be called with the string\n",
      "        of every JSON float to be decoded. By default this is equivalent to\n",
      "        float(num_str). This can be used to use another datatype or parser\n",
      "        for JSON floats (e.g. decimal.Decimal).\n",
      "        \n",
      "        ``parse_int``, if specified, will be called with the string\n",
      "        of every JSON int to be decoded. By default this is equivalent to\n",
      "        int(num_str). This can be used to use another datatype or parser\n",
      "        for JSON integers (e.g. float).\n",
      "        \n",
      "        ``parse_constant``, if specified, will be called with one of the\n",
      "        following strings: -Infinity, Infinity, NaN, null, true, false.\n",
      "        This can be used to raise an exception if invalid JSON numbers\n",
      "        are encountered.\n",
      "        \n",
      "        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n",
      "        kwarg; otherwise ``JSONDecoder`` is used.\n",
      "        \n",
      "        The ``encoding`` argument is ignored and deprecated.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['dump', 'dumps', 'load', 'loads', 'JSONDecoder', 'JSONDecod...\n",
      "\n",
      "VERSION\n",
      "    2.0.9\n",
      "\n",
      "AUTHOR\n",
      "    Bob Ippolito <bob@redivi.com>\n",
      "\n",
      "FILE\n",
      "    /Users/slackoverflow/anaconda3/lib/python3.5/json/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "help(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = dict(first='Bob', last='Smith')\n",
    "rec = dict(name=name, job=['dev', 'mgr'], age=40.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"job\": [\"dev\", \"mgr\"], \"age\": 40.5, \"name\": {\"first\": \"Bob\", \"last\": \"Smith\"}}'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = json.dumps(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o = json.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 40.5, 'job': ['dev', 'mgr'], 'name': {'first': 'Bob', 'last': 'Smith'}}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o == rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o['name'] == name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dump in module json:\n",
      "\n",
      "dump(obj, fp, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "    Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n",
      "    ``.write()``-supporting file-like object).\n",
      "    \n",
      "    If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "    instead of raising a ``TypeError``.\n",
      "    \n",
      "    If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n",
      "    contain non-ASCII characters if they appear in strings contained in\n",
      "    ``obj``. Otherwise, all such characters are escaped in JSON strings.\n",
      "    \n",
      "    If ``check_circular`` is false, then the circular reference check\n",
      "    for container types will be skipped and a circular reference will\n",
      "    result in an ``OverflowError`` (or worse).\n",
      "    \n",
      "    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n",
      "    in strict compliance of the JSON specification, instead of using the\n",
      "    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "    \n",
      "    If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "    object members will be pretty-printed with that indent level. An indent\n",
      "    level of 0 will only insert newlines. ``None`` is the most compact\n",
      "    representation.\n",
      "    \n",
      "    If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "    you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "    \n",
      "    ``default(obj)`` is a function that should return a serializable version\n",
      "    of obj or raise TypeError. The default simply raises TypeError.\n",
      "    \n",
      "    If *sort_keys* is ``True`` (default: ``False``), then the output of\n",
      "    dictionaries will be sorted by key.\n",
      "    \n",
      "    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "    ``.default()`` method to serialize additional types), specify it with\n",
      "    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(json.dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json.dump(rec, fp=open('testjson.txt', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"job\": [\n",
      "        \"dev\",\n",
      "        \"mgr\"\n",
      "    ],\n",
      "    \"age\": 40.5,\n",
      "    \"name\": {\n",
      "        \"first\": \"Bob\",\n",
      "        \"last\": \"Smith\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(open('testjson.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_io.TextIOWrapper"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(open('testjson.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(open('testjson.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 40.5, 'job': ['dev', 'mgr'], 'name': {'first': 'Bob', 'last': 'Smith'}}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person = json.load(open('testjson.txt'))\n",
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '{'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-f2dbde93d6ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testjson.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '{'."
     ]
    }
   ],
   "source": [
    "pickle.load(open('testjson.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have 'read' and 'readline' attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-6434f3ed25b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testjson.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: file must have 'read' and 'readline' attributes"
     ]
    }
   ],
   "source": [
    "for item in open('testjson.txt', 'rb'):\n",
    "    pickle.load(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    {\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for item in open('testjson.txt'):\n",
    "    eval(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-f2b9dfc10d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "help(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
